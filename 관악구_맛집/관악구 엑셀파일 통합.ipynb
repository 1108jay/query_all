{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5306e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\1108j\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: html5lib in c:\\users\\1108j\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\1108j\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from html5lib) (1.17.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\1108j\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from html5lib) (0.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28053b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ í´ë”: C:\\Users\\1108j\\OneDrive\\ë°”íƒ• í™”ë©´\\data prep\\ë§›ì§‘ ì¶”ì¶œ_ì‹œêµ°êµ¬\\Gwanak_Data\n",
      "ğŸ“„ íŒŒì¼ ê°œìˆ˜: 38ê°œ\n",
      "\n",
      "ğŸš€ ë°ì´í„° ë¡œë”© ì‹œì‘!\n",
      "[38/38] ì½ëŠ” ì¤‘... ì—…ë¬´ì¶”ì§„ë¹„_20260129 (9).xlss\n",
      "âœ… ë¡œë”© ì™„ë£Œ! ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ğŸ“Š ë³‘í•© ì™„ë£Œ (56170í–‰).\n",
      "ğŸ§  ë­í‚¹ ê³„ì‚° ì¤‘...\n",
      "ğŸ’¾ ì €ì¥ ì¤‘...\n",
      "\n",
      "ğŸ‰ [ì„±ê³µ] ë¶„ì„ ë! ì•„ë˜ íŒŒì¼ì„ ì—´ì–´ë³´ì„¸ìš”:\n",
      "ğŸ“‚ C:\\Users\\1108j\\OneDrive\\ë°”íƒ• í™”ë©´\\data prep\\ë§›ì§‘ ì¶”ì¶œ_ì‹œêµ°êµ¬\\Gwanak_Data\\ê´€ì•…êµ¬_ë§›ì§‘_ê²°ê³¼_ìµœì¢….xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "# ==========================================\n",
    "target_dir = r\"C:\\Users\\1108j\\OneDrive\\ë°”íƒ• í™”ë©´\\data prep\\ë§›ì§‘ ì¶”ì¶œ_ì‹œêµ°êµ¬\\Gwanak_Data\"\n",
    "file_list = glob.glob(os.path.join(target_dir, \"*.xls*\"))\n",
    "\n",
    "print(f\"ğŸ“‚ í´ë”: {target_dir}\")\n",
    "print(f\"ğŸ“„ íŒŒì¼ ê°œìˆ˜: {len(file_list)}ê°œ\")\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# ==========================================\n",
    "# 2. ë§ŒëŠ¥ íŒŒì¼ ì½ê¸° í•¨ìˆ˜ (HTML/Excel ìë™ íŒë³„)\n",
    "# ==========================================\n",
    "def read_weird_excel(filepath):\n",
    "    try:\n",
    "        # 1. ê·¸ëƒ¥ ì—‘ì…€ë¡œ ì½ê¸° (í˜¹ì‹œ ìœ—ì¤„ì— ì œëª©ì´ ìˆìœ¼ë©´ header=1ë¡œ ì¡°ì •)\n",
    "        return pd.read_excel(filepath)\n",
    "    except:\n",
    "        try:\n",
    "            # 2. HTMLë¡œ ì½ê¸° (euc-kr)\n",
    "            dfs = pd.read_html(filepath, encoding='euc-kr')\n",
    "            # í‘œê°€ ì—¬ëŸ¬ ê°œì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ê°€ì¥ ë°ì´í„° ë§ì€ ê±¸ ì„ íƒí•˜ê±°ë‚˜ ì²« ë²ˆì§¸ ê±¸ ì„ íƒ\n",
    "            if len(dfs) >= 1: return dfs[0]\n",
    "            else: return None\n",
    "        except:\n",
    "            try:\n",
    "                # 3. HTMLë¡œ ì½ê¸° (utf-8)\n",
    "                dfs = pd.read_html(filepath, encoding='utf-8')\n",
    "                return dfs[0]\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "# ==========================================\n",
    "# 3. ë°ì´í„° ë¡œë”© (ì‹¤ì‹œê°„ ì¤‘ê³„)\n",
    "# ==========================================\n",
    "print(\"\\nğŸš€ ë°ì´í„° ë¡œë”© ì‹œì‘!\")\n",
    "\n",
    "for i, file_path in enumerate(file_list):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f\"[{i+1}/{len(file_list)}] ì½ëŠ” ì¤‘... {file_name}\", end='\\r', flush=True)\n",
    "    \n",
    "    df = read_weird_excel(file_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # [ì¤‘ìš”] í˜¹ì‹œ ì²« ì¤„ì´ 'ì—…ë¬´ì¶”ì§„ë¹„ ëª©ë¡' ê°™ì€ ì œëª©ì´ë¼ë©´ ì‚­ì œí•˜ëŠ” ì•ˆì „ì¥ì¹˜\n",
    "        if 'ì§‘í–‰ì¥ì†Œ' not in df.columns:\n",
    "            # ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ë‹¤ì‹œ ì„¤ì • ì‹œë„\n",
    "            new_header = df.iloc[0] \n",
    "            df = df[1:] \n",
    "            df.columns = new_header\n",
    "\n",
    "        all_data.append(df)\n",
    "\n",
    "print(f\"\\nâœ… ë¡œë”© ì™„ë£Œ! ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. ë°ì´í„° ë³‘í•© ë° ë¶„ì„ (ìˆ˜ì •ëœ ì´ë¦„í‘œ ì ìš©!)\n",
    "# ==========================================\n",
    "if not all_data:\n",
    "    print(\"\\nâŒ ë°ì´í„°ë¥¼ ëª» ì½ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # ì»¬ëŸ¼ ì´ë¦„ ê³µë°± ì œê±° (ë§¤ìš° ì¤‘ìš”)\n",
    "    combined_df.columns = combined_df.columns.astype(str).str.strip()\n",
    "    \n",
    "    print(f\"ğŸ“Š ë³‘í•© ì™„ë£Œ ({len(combined_df)}í–‰).\")\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # [ìˆ˜ì •ë¨] ì‚¬ì§„ ë³´ê³  ë˜‘ê°™ì´ ë§ì¶˜ ì´ë¦„í‘œ!\n",
    "    # ---------------------------------------------------------------\n",
    "    col_place = 'ì§‘í–‰ì¥ì†Œ'\n",
    "    col_day = 'ì§‘í–‰ì¼'\n",
    "    col_time = 'ì§‘í–‰ì‹œê°„'\n",
    "    col_amount = 'ì§‘í–‰ê¸ˆì•¡(ì›)'  # ì‚¬ì§„ì— (ì›) ìˆìŒ\n",
    "    col_people = 'ëŒ€ìƒì¸ì›ìˆ˜'    # ì‚¬ì§„ì— (ëª…) ì—†ìŒ! (ì—¬ê¸°ê°€ ë¬¸ì œì˜€ìŒ)\n",
    "\n",
    "    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬\n",
    "    if col_place not in combined_df.columns:\n",
    "        print(f\"ğŸš¨ [ì—ëŸ¬] '{col_place}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(combined_df.columns)}\")\n",
    "    else:\n",
    "        # 1. ì¥ì†Œëª… ì •ì œ (ê´„í˜¸ ì œê±°)\n",
    "        combined_df['ì •ì œëœì¥ì†Œëª…'] = combined_df[col_place].astype(str).str.split('(').str[0].str.strip()\n",
    "        \n",
    "        # 2. ìˆ«ì ë³€í™˜ (ì½¤ë§ˆ ì œê±°)\n",
    "        for col in [col_amount, col_people]:\n",
    "            if col in combined_df.columns:\n",
    "                # ìˆ«ìê°€ ì•„ë‹Œ ê²ƒë“¤ì€ 0ìœ¼ë¡œ ë³€í™˜ (errors='coerce')\n",
    "                combined_df[col] = pd.to_numeric(combined_df[col].astype(str).str.replace(',', ''), errors='coerce').fillna(0)\n",
    "            else:\n",
    "                print(f\"âš ï¸ ê²½ê³ : '{col}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        # 3. 1ì¸ë‹¹ ê¸ˆì•¡ ê³„ì‚°\n",
    "        if col_people in combined_df.columns and col_amount in combined_df.columns:\n",
    "             combined_df['1ì¸ë‹¹ê¸ˆì•¡'] = combined_df.apply(\n",
    "                lambda x: x[col_amount] / x[col_people] if x[col_people] > 0 else 0, axis=1\n",
    "            )\n",
    "        else:\n",
    "            print(\"âš ï¸ 'ê¸ˆì•¡' ë˜ëŠ” 'ì¸ì›' ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ [ê°€ì„±ë¹„ ë¶„ì„]ì€ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            combined_df['1ì¸ë‹¹ê¸ˆì•¡'] = 0 # ì—ëŸ¬ ë°©ì§€ìš© 0 ì±„ìš°ê¸°\n",
    "\n",
    "        # 4. ë‚ ì§œ ë³€í™˜\n",
    "        if col_day in combined_df.columns:\n",
    "            combined_df[col_day] = pd.to_datetime(combined_df[col_day], errors='coerce')\n",
    "\n",
    "        # 5. ì‹œê°„ ë³€í™˜ (ì‹œ:ë¶„:ì´ˆ or ì‹œ:ë¶„) -> 'ì‹œ'(Hour) ì¶”ì¶œ\n",
    "        def extract_hour(time_val):\n",
    "            try:\n",
    "                time_str = str(time_val).strip()\n",
    "                if ':' in time_str: # 12:30 í˜•íƒœ\n",
    "                    return int(time_str.split(':')[0])\n",
    "                elif 'ì‹œ' in time_str: # 12ì‹œ í˜•íƒœ\n",
    "                    return int(re.search(r'(\\d+)ì‹œ', time_str).group(1))\n",
    "                else:\n",
    "                    return None\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        if col_time in combined_df.columns:\n",
    "            combined_df['ì‹œê°'] = combined_df[col_time].apply(extract_hour)\n",
    "        else:\n",
    "            combined_df['ì‹œê°'] = None\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # ë­í‚¹ ì‚°ì¶œ\n",
    "        # ----------------------------------------------------\n",
    "        def get_ranking(df, title):\n",
    "            if df.empty: return pd.DataFrame(columns=['ì‹ë‹¹ì´ë¦„', 'ë°©ë¬¸íšŸìˆ˜'])\n",
    "            ranking = df['ì •ì œëœì¥ì†Œëª…'].value_counts().reset_index()\n",
    "            ranking.columns = ['ì‹ë‹¹ì´ë¦„', 'ë°©ë¬¸íšŸìˆ˜']\n",
    "            \n",
    "            # í‰ê·  1ì¸ë‹¹ ê¸ˆì•¡ ì •ë³´ ì¶”ê°€\n",
    "            if '1ì¸ë‹¹ê¸ˆì•¡' in df.columns:\n",
    "                avg_price = df.groupby('ì •ì œëœì¥ì†Œëª…')['1ì¸ë‹¹ê¸ˆì•¡'].mean().round(0)\n",
    "                ranking = ranking.merge(avg_price, left_on='ì‹ë‹¹ì´ë¦„', right_index=True, how='left')\n",
    "                ranking.rename(columns={'1ì¸ë‹¹ê¸ˆì•¡': 'í‰ê· 1ì¸ë‹¹ê¸ˆì•¡'}, inplace=True)\n",
    "            return ranking\n",
    "\n",
    "        print(\"ğŸ§  ë­í‚¹ ê³„ì‚° ì¤‘...\", flush=True)\n",
    "        \n",
    "        # 1. ì „ì²´ ë­í‚¹\n",
    "        rank_total = get_ranking(combined_df, \"ì „ì²´\")\n",
    "        \n",
    "        # 2. ìµœì‹ ìˆœ\n",
    "        if col_day in combined_df.columns:\n",
    "            df_recent = combined_df.sort_values(by=col_day, ascending=False)\n",
    "        else:\n",
    "            df_recent = combined_df\n",
    "\n",
    "        # 3. ì ì‹¬/ì €ë…\n",
    "        rank_lunch = get_ranking(combined_df[(combined_df['ì‹œê°'] >= 11) & (combined_df['ì‹œê°'] <= 14)], \"ì ì‹¬\")\n",
    "        rank_dinner = get_ranking(combined_df[combined_df['ì‹œê°'] >= 17], \"ì €ë…\")\n",
    "        \n",
    "        # 4. ê°€ì„±ë¹„/ê³ ê¸‰\n",
    "        rank_cheap = get_ranking(combined_df[(combined_df['1ì¸ë‹¹ê¸ˆì•¡'] >= 10000) & (combined_df['1ì¸ë‹¹ê¸ˆì•¡'] < 20000)], \"1ë§Œì›ëŒ€\")\n",
    "        rank_expensive = get_ranking(combined_df[combined_df['1ì¸ë‹¹ê¸ˆì•¡'] >= 30000], \"3ë§Œì›ì´ìƒ\")\n",
    "\n",
    "        # ì—‘ì…€ ì €ì¥\n",
    "        save_path = os.path.join(target_dir, \"ê´€ì•…êµ¬_ë§›ì§‘_ê²°ê³¼_ìµœì¢….xlsx\")\n",
    "        print(\"ğŸ’¾ ì €ì¥ ì¤‘...\", flush=True)\n",
    "        \n",
    "        with pd.ExcelWriter(save_path) as writer:\n",
    "            rank_total.head(100).to_excel(writer, sheet_name='1_ì „ì²´ë­í‚¹', index=False)\n",
    "            df_recent.head(100).to_excel(writer, sheet_name='2_ìµœì‹ ë°ì´í„°', index=False)\n",
    "            rank_lunch.head(50).to_excel(writer, sheet_name='3_ì ì‹¬', index=False)\n",
    "            rank_dinner.head(50).to_excel(writer, sheet_name='4_ì €ë…', index=False)\n",
    "            \n",
    "            if not rank_cheap.empty:\n",
    "                rank_cheap.head(50).to_excel(writer, sheet_name='5_1ë§Œì›ëŒ€', index=False)\n",
    "            if not rank_expensive.empty:\n",
    "                rank_expensive.head(50).to_excel(writer, sheet_name='6_3ë§Œì›ì´ìƒ', index=False)\n",
    "\n",
    "        print(f\"\\nğŸ‰ [ì„±ê³µ] ë¶„ì„ ë! ì•„ë˜ íŒŒì¼ì„ ì—´ì–´ë³´ì„¸ìš”:\\nğŸ“‚ {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
