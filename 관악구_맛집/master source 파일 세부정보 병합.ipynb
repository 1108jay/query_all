{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8069e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì—¬ê¸°ë¥¼ ê¼­ í™•ì¸í•´ì£¼ì„¸ìš”!)\n",
    "# ==========================================\n",
    "base_dir = os.path.join(os.getcwd(), \"Gwanak_Data\")\n",
    "\n",
    "# Clean í´ë” ìš°ì„  ì‚¬ìš©\n",
    "clean_dir = os.path.join(base_dir, \"Clean_XLSX\")\n",
    "if os.path.exists(clean_dir) and len(glob.glob(os.path.join(clean_dir, \"*.xlsx\"))) > 0:\n",
    "    source_dir = clean_dir\n",
    "else:\n",
    "    source_dir = base_dir\n",
    "\n",
    "# â˜…â˜…â˜… [ì¤‘ìš”] ìˆ˜ì‘ì—…í•œ ì •ë‹µ íŒŒì¼ ì´ë¦„ â˜…â˜…â˜…\n",
    "# íŒŒì¼ ì´ë¦„ì´ ì •í™•í•œì§€ ê¼­ í™•ì¸í•´ì£¼ì„¸ìš”! (í™•ì¥ìê¹Œì§€)\n",
    "manual_file_name = \"ê´€ì•…êµ¬_ë§›ì§‘_ë§ˆìŠ¤í„°_ë¹ˆë„í¬í•¨_ê°€ë‚˜ë‹¤ìˆœ.xlsx\" \n",
    "# ë§Œì•½ csvë¼ë©´ \"ê´€ì•…êµ¬_ë§›ì§‘_ë§ˆìŠ¤í„°_ë¹ˆë„í¬í•¨_ê°€ë‚˜ë‹¤ìˆœ.csv\" ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.\n",
    "\n",
    "manual_file_path = os.path.join(base_dir, manual_file_name)\n",
    "\n",
    "# ==========================================\n",
    "# 2. ì •ë‹µì§€(ìˆ˜ì‘ì—… ë¦¬ìŠ¤íŠ¸) ë¡œë”© (ë¬´ì  ë¡œì§)\n",
    "# ==========================================\n",
    "print(f\"ğŸ“‹ ì •ë‹µ ë¦¬ìŠ¤íŠ¸ ì½ê¸° ì‹œë„: {manual_file_path}\")\n",
    "\n",
    "if not os.path.exists(manual_file_path):\n",
    "    print(f\"ğŸš¨ [ì—ëŸ¬] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! ê²½ë¡œì™€ íŒŒì¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    print(f\"ğŸ‘‰ ì°¾ëŠ” ê²½ë¡œ: {manual_file_path}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # 1) ì—‘ì…€(.xlsx)ì¸ ê²½ìš°\n",
    "    if manual_file_name.endswith('.xlsx') or manual_file_name.endswith('.xls'):\n",
    "        valid_df = pd.read_excel(manual_file_path)\n",
    "    # 2) CSV(.csv)ì¸ ê²½ìš° (ì¸ì½”ë”© ìë™ ì‹œë„)\n",
    "    else:\n",
    "        try:\n",
    "            valid_df = pd.read_csv(manual_file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                valid_df = pd.read_csv(manual_file_path, encoding='cp949')\n",
    "            except UnicodeDecodeError:\n",
    "                valid_df = pd.read_csv(manual_file_path, encoding='euc-kr')\n",
    "\n",
    "    # ì»¬ëŸ¼ ì´ë¦„ í™•ì¸ ë° ë³´ì •\n",
    "    print(f\"ğŸ‘€ íŒŒì¼ì— ìˆëŠ” ì»¬ëŸ¼ë“¤: {list(valid_df.columns)}\")\n",
    "    \n",
    "    target_col = 'ì‹ë‹¹ì´ë¦„'\n",
    "    if target_col not in valid_df.columns:\n",
    "        # 'ì‹ë‹¹ì´ë¦„' ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´, ë¬´ì¡°ê±´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ì‹ë‹¹ ì´ë¦„ìœ¼ë¡œ ì”ë‹ˆë‹¤.\n",
    "        target_col = valid_df.columns[0]\n",
    "        print(f\"âš ï¸ 'ì‹ë‹¹ì´ë¦„' ì»¬ëŸ¼ì„ ëª» ì°¾ì•„ì„œ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì¸ '{target_col}'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ì •ë‹µ ì‹ë‹¹ ì´ë¦„ í™•ë³´\n",
    "    valid_names = set(valid_df[target_col].astype(str).str.strip().tolist())\n",
    "    print(f\"âœ… ì´ {len(valid_names)}ê°œì˜ ì •ë‹µ ì‹ë‹¹ ì´ë¦„ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ íŒŒì¼ì„ ì½ëŠ” ë„ì¤‘ ì¹˜ëª…ì ì¸ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\\n{e}\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 3. ì›ë³¸ ë°ì´í„° ë¡œë”© & ë§¤ì¹­\n",
    "# ==========================================\n",
    "print(\"ë°ì´í„° ë³µì› ë° ë§¤ì¹­ ì¤‘...\", end='', flush=True)\n",
    "\n",
    "file_list = glob.glob(os.path.join(source_dir, \"*.xls*\"))\n",
    "all_data = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    # ìˆ˜ì‘ì—… íŒŒì¼ì´ë‚˜ ê²°ê³¼ íŒŒì¼ì€ ì½ì§€ ì•Šë„ë¡ ì œì™¸\n",
    "    if manual_file_name in file_path or \"ê²°ê³¼\" in file_path or \"í†µí•©ë³¸\" in file_path: continue\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        if 'ì§‘í–‰ì¥ì†Œ' not in df.columns:\n",
    "            for idx, row in df.iterrows():\n",
    "                if 'ì§‘í–‰ì¥ì†Œ' in row.values:\n",
    "                    df.columns = row\n",
    "                    df = df[idx+1:]\n",
    "                    break\n",
    "        all_data.append(df)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if not all_data:\n",
    "    print(\"\\nâŒ ì›ë³¸ ë°ì´í„°ë¥¼ í•˜ë‚˜ë„ ëª» ì½ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    exit()\n",
    "\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "combined_df.columns = combined_df.columns.astype(str).str.strip()\n",
    "\n",
    "col_place = 'ì§‘í–‰ì¥ì†Œ'\n",
    "if col_place not in combined_df.columns:\n",
    "    print(\"\\nğŸš¨ ì›ë³¸ ë°ì´í„°ì—ì„œ 'ì§‘í–‰ì¥ì†Œ' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    exit()\n",
    "\n",
    "# ê´„í˜¸ ì œê±° í›„ ì„ì‹œ ì´ë¦„ ìƒì„±\n",
    "combined_df['ì„ì‹œì¥ì†Œëª…'] = combined_df[col_place].astype(str).str.split('(').str[0].str.strip()\n",
    "\n",
    "# â˜… í•µì‹¬: ì •ë‹µ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ì‹ë‹¹ë§Œ ë‚¨ê¸°ê¸° (Reverse Mapping)\n",
    "matched_df = combined_df[combined_df['ì„ì‹œì¥ì†Œëª…'].isin(valid_names)]\n",
    "\n",
    "print(\" ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š ë§¤ì¹­ ê²°ê³¼: ì›ë³¸ {len(combined_df)}ê±´ ì¤‘ {len(matched_df)}ê±´ì´ ì •ë‹µ ë¦¬ìŠ¤íŠ¸ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. ìƒì„¸ ì •ë³´ ê³„ì‚°\n",
    "# ==========================================\n",
    "col_amount = 'ì§‘í–‰ê¸ˆì•¡(ì›)'\n",
    "col_people = 'ëŒ€ìƒì¸ì›ìˆ˜'\n",
    "col_day = 'ì§‘í–‰ì¼'\n",
    "col_time = 'ì§‘í–‰ì‹œê°„'\n",
    "\n",
    "# ìˆ«ì ë³€í™˜\n",
    "for col in [col_amount, col_people]:\n",
    "    if col in matched_df.columns:\n",
    "        matched_df[col] = pd.to_numeric(matched_df[col].astype(str).str.replace(',', ''), errors='coerce').fillna(0)\n",
    "\n",
    "# 1ì¸ë‹¹ ê¸ˆì•¡\n",
    "if col_amount in matched_df.columns and col_people in matched_df.columns:\n",
    "    matched_df['1ì¸ë‹¹ê¸ˆì•¡'] = matched_df.apply(\n",
    "        lambda x: x[col_amount] / x[col_people] if x[col_people] > 0 else 0, axis=1\n",
    "    )\n",
    "else:\n",
    "    matched_df['1ì¸ë‹¹ê¸ˆì•¡'] = 0\n",
    "\n",
    "# ë‚ ì§œ & ì‹œê°„\n",
    "if col_day in matched_df.columns:\n",
    "    matched_df[col_day] = pd.to_datetime(matched_df[col_day], errors='coerce')\n",
    "\n",
    "def extract_hour(time_val):\n",
    "    try:\n",
    "        time_str = str(time_val).strip()\n",
    "        if ':' in time_str: return int(time_str.split(':')[0])\n",
    "        elif 'ì‹œ' in time_str: return int(re.search(r'(\\d+)ì‹œ', time_str).group(1))\n",
    "        else: return None\n",
    "    except: return None\n",
    "    \n",
    "if col_time in matched_df.columns:\n",
    "    matched_df['ì‹œê°'] = matched_df[col_time].apply(extract_hour)\n",
    "else:\n",
    "    matched_df['ì‹œê°'] = None\n",
    "\n",
    "# ==========================================\n",
    "# 5. ë§ˆìŠ¤í„° í…Œì´ë¸” ìƒì„± (ì§‘ê³„)\n",
    "# ==========================================\n",
    "print(\"ğŸ“Š ìƒì„¸ ì •ë³´ ì§‘ê³„ ì¤‘...\")\n",
    "\n",
    "one_year_ago = datetime.now() - timedelta(days=365)\n",
    "\n",
    "# ì¡°ê±´ í”Œë˜ê·¸ ìƒì„±\n",
    "matched_df['is_recent'] = matched_df[col_day].apply(lambda x: 1 if pd.notnull(x) and x >= one_year_ago else 0)\n",
    "matched_df['is_lunch'] = matched_df['ì‹œê°'].apply(lambda x: 1 if pd.notnull(x) and 11 <= x <= 14 else 0)\n",
    "matched_df['is_dinner'] = matched_df['ì‹œê°'].apply(lambda x: 1 if pd.notnull(x) and x >= 17 else 0)\n",
    "matched_df['is_cheap'] = matched_df['1ì¸ë‹¹ê¸ˆì•¡'].apply(lambda x: 1 if 10000 <= x < 20000 else 0)\n",
    "matched_df['is_expensive'] = matched_df['1ì¸ë‹¹ê¸ˆì•¡'].apply(lambda x: 1 if x >= 30000 else 0)\n",
    "\n",
    "# ì‹ë‹¹ë³„ë¡œ ë¬¶ì–´ì„œ í†µê³„ ë‚´ê¸°\n",
    "master_df = matched_df.groupby('ì„ì‹œì¥ì†Œëª…').agg(\n",
    "    ì´ë°©ë¬¸íšŸìˆ˜=('ì„ì‹œì¥ì†Œëª…', 'count'),\n",
    "    í‰ê· 1ì¸ë‹¹ê¸ˆì•¡=('1ì¸ë‹¹ê¸ˆì•¡', 'mean'),\n",
    "    ìµœê·¼1ë…„_ë°©ë¬¸ìˆ˜=('is_recent', 'sum'),\n",
    "    ì ì‹¬_ë°©ë¬¸ìˆ˜=('is_lunch', 'sum'),\n",
    "    ì €ë…_ë°©ë¬¸ìˆ˜=('is_dinner', 'sum'),\n",
    "    ê°€ì„±ë¹„_ë°©ë¬¸ìˆ˜=('is_cheap', 'sum'),\n",
    "    ê³ ê¸‰_ë°©ë¬¸ìˆ˜=('is_expensive', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "master_df['í‰ê· 1ì¸ë‹¹ê¸ˆì•¡'] = master_df['í‰ê· 1ì¸ë‹¹ê¸ˆì•¡'].round(0)\n",
    "master_df.rename(columns={'ì„ì‹œì¥ì†Œëª…': 'ì‹ë‹¹ì´ë¦„'}, inplace=True)\n",
    "\n",
    "# ê°€ë‚˜ë‹¤ìˆœ ì •ë ¬\n",
    "master_df = master_df.sort_values(by='ì‹ë‹¹ì´ë¦„')\n",
    "\n",
    "# ==========================================\n",
    "# 6. ì €ì¥\n",
    "# ==========================================\n",
    "save_path = os.path.join(base_dir, \"ê´€ì•…êµ¬_ë§›ì§‘_ìƒì„¸ì •ë³´_í†µí•©ë³¸.xlsx\")\n",
    "print(\"ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...\")\n",
    "\n",
    "master_df.to_excel(save_path, index=False)\n",
    "\n",
    "print(f\"\\nğŸ‰ [ì„±ê³µ] ì´ë²ˆì—” ì§„ì§œ ëìŠµë‹ˆë‹¤! ì—ëŸ¬ ì—†ì´ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“‚ íŒŒì¼ ìœ„ì¹˜: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10íšŒ ë¯¸ë§Œ ë°©ë¬¸íšŸìˆ˜ ì‚­ì œ\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. íŒŒì¼ ì°¾ê¸° (ìë™ ê°ì§€)\n",
    "# ==========================================\n",
    "base_dir = r\"C:\\Users\\1108j\\OneDrive\\ë°”íƒ• í™”ë©´\\data prep\\ë§›ì§‘ ì¶”ì¶œ_ì‹œêµ°êµ¬\\Gwanak_Data\"\n",
    "\n",
    "# Clean í´ë”ê°€ ìˆìœ¼ë©´ ê±°ê¸°ë¶€í„° ë´…ë‹ˆë‹¤\n",
    "if os.path.exists(os.path.join(base_dir, \"Clean_XLSX\")):\n",
    "    search_dir = os.path.join(base_dir, \"Clean_XLSX\")\n",
    "else:\n",
    "    search_dir = base_dir\n",
    "\n",
    "print(f\"ğŸ“‚ í´ë”ì—ì„œ 'í†µí•©ë³¸' íŒŒì¼ì„ ì°¾ëŠ” ì¤‘... ({search_dir})\")\n",
    "\n",
    "# 'í†µí•©ë³¸'ì´ë¼ëŠ” ë‹¨ì–´ê°€ ë“¤ì–´ê°€ëŠ” ì—‘ì…€ì´ë‚˜ CSV íŒŒì¼ì„ ë‹¤ ì°¾ìŠµë‹ˆë‹¤.\n",
    "candidates = glob.glob(os.path.join(search_dir, \"*í†µí•©ë³¸*.*\"))\n",
    "\n",
    "if not candidates:\n",
    "    # ëª» ì°¾ì•˜ìœ¼ë©´ ìƒìœ„ í´ë”ë„ í•œ ë²ˆ ë” ë’¤ì§‘ë‹ˆë‹¤\n",
    "    candidates = glob.glob(os.path.join(base_dir, \"*í†µí•©ë³¸*.*\"))\n",
    "\n",
    "if not candidates:\n",
    "    print(\"âŒ 'í†µí•©ë³¸' íŒŒì¼ì„ ëª» ì°¾ê² ì–´ìš”! íŒŒì¼ ì´ë¦„ì— 'í†µí•©ë³¸'ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    exit()\n",
    "\n",
    "target_file = candidates[0] # ì²« ë²ˆì§¸ë¡œ ë°œê²¬ëœ ë†ˆì„ ì¡ìŠµë‹ˆë‹¤.\n",
    "print(f\"ğŸ‘‰ ë°œê²¬ëœ íŒŒì¼: {target_file}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. íŒŒì¼ ì½ê¸° (ì—‘ì…€/CSV êµ¬ë¶„)\n",
    "# ==========================================\n",
    "try:\n",
    "    if target_file.endswith('.csv'):\n",
    "        # CSVë©´ ì¸ì½”ë”© ì—¬ëŸ¬ ê°œ ì‹œë„\n",
    "        try:\n",
    "            df = pd.read_csv(target_file, encoding='utf-8')\n",
    "        except:\n",
    "            df = pd.read_csv(target_file, encoding='cp949')\n",
    "    else:\n",
    "        # ì—‘ì…€ì´ë©´ ê·¸ëƒ¥ ì½ê¸°\n",
    "        df = pd.read_excel(target_file)\n",
    "    \n",
    "    print(f\"ğŸ“Š ë°ì´í„° ë¡œë”© ì„±ê³µ! (ì´ {len(df)}ê°œ ì‹ë‹¹)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ íŒŒì¼ì„ ì½ë‹¤ê°€ ì—ëŸ¬ê°€ ë‚¬ì–´ìš”: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 3. 10íšŒ ë¯¸ë§Œ ì‚­ì œ (í•„í„°ë§)\n",
    "# ==========================================\n",
    "col_count = 'ì´ë°©ë¬¸íšŸìˆ˜'\n",
    "\n",
    "if col_count not in df.columns:\n",
    "    print(f\"ğŸš¨ '{col_count}' ì»¬ëŸ¼ì´ ì•ˆ ë³´ì—¬ìš”. ì»¬ëŸ¼ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    print(f\"í˜„ì¬ ì»¬ëŸ¼ ëª©ë¡: {list(df.columns)}\")\n",
    "else:\n",
    "    # ìˆ«ì ë³€í™˜ (í˜¹ì‹œ ë¬¸ìë¡œ ë˜ì–´ ìˆì„ê¹Œë´ ì•ˆì „ì¥ì¹˜)\n",
    "    df[col_count] = pd.to_numeric(df[col_count], errors='coerce').fillna(0)\n",
    "    \n",
    "    # 10íšŒ ì´ìƒ í•„í„°ë§\n",
    "    filtered_df = df[df[col_count] >= 10]\n",
    "    \n",
    "    print(f\"âœ‚ï¸ 10íšŒ ë¯¸ë§Œ ì‚­ì œ ì™„ë£Œ! ({len(df)}ê°œ -> {len(filtered_df)}ê°œ)\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. ì €ì¥\n",
    "    # ==========================================\n",
    "    save_path = os.path.join(base_dir, \"ê´€ì•…êµ¬_ë§›ì§‘_ìµœì¢…_10íšŒì´ìƒ.xlsx\")\n",
    "    \n",
    "    filtered_df.to_excel(save_path, index=False)\n",
    "    print(f\"\\nğŸ‰ [ì„±ê³µ] ì €ì¥ ì™„ë£Œ!\\nğŸ“‚ íŒŒì¼ ìœ„ì¹˜: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
